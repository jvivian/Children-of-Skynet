{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements \n",
    "\n",
    "- Tensorflow, if you have anaconda `conda install tensorflow`\n",
    "- `pip install -y pandas numpy keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @GOPChairwoman: .@realDonaldTrump is the Pa...</td>\n",
       "      <td>12-14-2017 23:26:54</td>\n",
       "      <td>4262</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>941449449850761217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“Manufacturing Optimism Rose to Another All-Ti...</td>\n",
       "      <td>12-14-2017 21:20:51</td>\n",
       "      <td>4789</td>\n",
       "      <td>19906</td>\n",
       "      <td>False</td>\n",
       "      <td>941417725833998340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  RT @GOPChairwoman: .@realDonaldTrump is the Pa...   \n",
       "1  Twitter for iPhone  “Manufacturing Optimism Rose to Another All-Ti...   \n",
       "\n",
       "               created  retweets  favorites  is_retweet                  id  \n",
       "0  12-14-2017 23:26:54      4262          0        True  941449449850761217  \n",
       "1  12-14-2017 21:20:51      4789      19906       False  941417725833998340  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/tweets-fixed.tsv', sep='\\t', index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanitize tweets into a format suitable for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3306514"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a set of characters to remove to reduce our vocab set\n",
    "chars_to_remove = {'\"', '$', '%', \"'\", '(', ')', '*', '+', '/', ';', \n",
    "                   '<', '=', '>', '[', '\\\\', ']', '_', '`',  '{', '|', '}', '~'}\n",
    "                    #'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '#',\n",
    "# In 32,000 tweets he apparently never uses a comma, probably an artifact of CSV export.    \n",
    "\n",
    "# TODO: Order tweets\n",
    "\n",
    "text = ''\n",
    "for i, tweet in enumerate(df[df.is_retweet == False].text):\n",
    "    # print tweet\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    \n",
    "    # Fix ampersand HTML artifact\n",
    "    tweet = tweet.replace('&amp;', '&')\n",
    "    \n",
    "    # lower() to reduce pool of possible characters (lower-case's strings)\n",
    "    # the decode/encode step is to remove non-ascii characters like \n",
    "    tweet = tweet.lower().decode(\"ascii\", errors=\"ignore\").encode()\n",
    "\n",
    "    # Remove chars from our chars_to_remove set with list comprehension\n",
    "    for x in chars_to_remove:\n",
    "        tweet = tweet.replace(x, ' ')\n",
    "    #tweet = ''.join([x for x in tweet if x not in chars_to_remove]).rstrip()\n",
    "    \n",
    "    # If there's no tweet left (just a URL for example)\n",
    "    if not tweet:\n",
    "        continue\n",
    "        \n",
    "    # split and rejoin for odd spacing\n",
    "    tweet = ' '.join(tweet.split())        \n",
    "    \n",
    "    # Add period if no ending line or a space\n",
    "    if not tweet[-1] in ['.', '!', '?']:\n",
    "        tweet = tweet + '. '\n",
    "    else:\n",
    "        tweet += ' '\n",
    "\n",
    "    # Add to text (by redefining with +=)\n",
    "    text += tweet\n",
    "    \n",
    "    #print tweet, '\\n'\n",
    "    #print\n",
    "    # if i > 100: break\n",
    "    \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create character set and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 45\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print 'Total chars: {}'.format(len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut text up into arbitrary sequences using a maximum length and a step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb sequences:', 1102158)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization of inputs\n",
    "\n",
    "- x: has dimensionality (num_sequences, maxlength, num_chars)\n",
    "- y: has dimensionality (num_sequences, num_chars)\n",
    "\n",
    "A sequence in `x` is represented as a 2d matrix of `maxlength` by `num_chars`. This means each row corresponds to what character in the possible character set, with every value being 0 except for a 1 in the position corresponding to the character. For example, the letter 'a' corresponds to the 19th position (column) in the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example from above\n",
    "char_indices['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by creating arrays of zeros with our final dimensionality\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll build a simple LSTM model to start with that will likely need to be tweaked to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest model abstraction is Sequential\n",
    "model = Sequential()\n",
    "# Add LSTM layer with 256 memory units\n",
    "model.add(LSTM(256, input_shape=(maxlen, len(chars))))\n",
    "# Add Dropout layer at 20% node dropout (avoids overfitting)\n",
    "model.add(Dropout(0.2))\n",
    "# Add final Dense layer which corresponds to each of our characters\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "# Compile the model \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use checkpointing and select the final set of weights with the lowest loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCheckpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory for model output\n",
    "if not os.path.exists('model'):\n",
    "    os.mkdir('model')\n",
    "\n",
    "path = \"model/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model with weights corresponding to smallest loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weights-improvement-20-1.2692.hdf5']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = os.path.join('model', os.listdir('model')[0])  # Grab weight in model dir\n",
    "model.load_weights(weights)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull out random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with seed: & russia. great night in iowa - special \n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "generated = ''\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "generated += sentence\n",
    "print 'Generating with seed: {}\\n'.format(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text from seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_input(sentence, maxlen, chars, char_indices):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "    return x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& russia. great night in iowa - special course in the u.s. in the world s starting to the presidential republicans are a great presidential and the real man and the world s strong and start to the presidential republicans are a great presidential and the real man and the world s strong and start to the presidential republicans are a great presidential and the real man and the world s strong and start to the presidential republicans are a [  2.73892860e-04   1.39975906e-04   3.91857931e-03   2.14983523e-03\n",
      "   1.23859849e-03   3.47654248e-04   1.93723354e-05   2.35167914e-03\n",
      "   1.11452281e-03   1.67771461e-04   2.32513470e-04   4.05182102e-04\n",
      "   7.20372118e-05   1.64037338e-04   1.02123391e-04   1.08421336e-04\n",
      "   1.72666605e-05   3.11164367e-05   4.16096766e-03   2.10555628e-01\n",
      "   3.49141285e-02   2.49546021e-02   3.07344217e-02   1.66234393e-02\n",
      "   4.43036482e-02   4.46878523e-02   3.08000762e-02   4.74325530e-02\n",
      "   1.05540482e-02   4.00115922e-03   2.75060702e-02   2.39861310e-02\n",
      "   5.54244928e-02   3.96022499e-02   1.74548998e-02   1.45773357e-03\n",
      "   2.66669430e-02   6.85432628e-02   1.36519894e-01   1.39087336e-02\n",
      "   1.06392931e-02   4.90760654e-02   2.59320714e-05   1.23686455e-02\n",
      "   2.42455062e-04]\n"
     ]
    }
   ],
   "source": [
    "sys.stdout.write(generated)\n",
    "for i in range(400):\n",
    "    # Convert text seed to input\n",
    "    x_pred = str_to_input(sentence, maxlen, chars, char_indices)\n",
    "    \n",
    "    # Make prediction with model\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_char = indices_char[np.argmax(preds)]\n",
    "\n",
    "    # Generate text\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "    #sys.stdout.write(next_char)\n",
    "    #sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
